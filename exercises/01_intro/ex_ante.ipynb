{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 \n",
    "\n",
    "The purpose of this week's excercise is twofold: First, introduce you to Numpy and making you familiar to the library and some of its pitfalls. Secondly, you will use this knowledge to estimate the linear model using OLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A short introduction to Numpy and Linear Algebra (Linalg)\n",
    "First, import all necessary packages. If you are missing a package, you can either install it through your terminal using pip, or an Anaconda terminal using conda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "from numpy import random as random\n",
    "from tabulate import tabulate\n",
    "#(NB if you havent got tabulate yet, install it using pip install tabulate)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entering matrices manually\n",
    "To create a $1\\times9$ *row* vector write,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "row = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a $9\\times1$ *column* vector write,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n"
     ]
    }
   ],
   "source": [
    "col = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9]])\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easier method is to define a row vector, and transpose it. Notice the double [[]]. Try to see what happens if you transpose a row vector using only []."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n"
     ]
    }
   ],
   "source": [
    "col = np.array([[1, 2, 3, 4, 5, 6, 7, 8, 9]]).T\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A short note on numpy vectors**\n",
    "Numpy does not treat vectors and matrices the same. A *true* numpy vector has the shape (k,), . The shape of a numpy array is an attribute, how do you call this attribute for the `row` and `col` arrays? What is the shape of the `row.T` array? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the shape attribute for the row and col vars. Check the shape of row.T\n",
    "\n",
    "# FILL IN HERE\n",
    "\n",
    "a = np.array([[1,2],[3,4]])\n",
    "v = np.array([1,2,3])\n",
    "\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a matrix, you combine what you have learned to manually create a $3 \\times 3$ matrix called x, that has the numbers 0 to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FILL IN HERE\n",
    "\n",
    "x = np.array([[0,1,2],[3,4,5],[6,7,8]])\n",
    "\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the same $3 \\times 3$ using `np.arange()` and np.reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FILL IN HERE\n",
    "\n",
    "X = np.arange(9)\n",
    "\n",
    "X = x.reshape((3,3))\n",
    "\n",
    "X.shape\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix calculations \n",
    "There are several types of matrix calculations available to us with the numpy library, and we will introduce some here.\n",
    "\n",
    "For matrix **multiplication** you can for the matrices `a` and `b` use `a@b`, `np.dot(a, b)` or `a.dot(b)`\n",
    "\n",
    "Use the `row`, `col` vectors and `x` matrix and perform these matrix multiplications. Does the `row` vector behave as you would expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: [1 2 3 4 5 6 7 8 9]\n",
      "Col: [[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "row@col: [285]\n"
     ]
    }
   ],
   "source": [
    "# FILL IN HERE\n",
    "\n",
    "aa = row@col\n",
    "aaa = np.dot(row, col)\n",
    "aaaa = row.dot(col)\n",
    "\n",
    "print(\"Row:\", row)\n",
    "print(\"Col:\", col)\n",
    "\n",
    "print(\"row@col:\", aaaa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if you use `/` and `*` operators with the  `row` and `col` vectors or the `x` matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN HERE\n",
    "\n",
    "mm = x*x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For OLS we need to be able to calculate the inverse. This is done with the `linalg` submodule. Create a new matrix that we can calculate the inverse on. Why can't we take the inverse of `x`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN HERE\n",
    "\n",
    "matrix = np.array([[0,1,2],[3,4,5],[6,7,8]])\n",
    "# la.inv(matrix) # linalg imported as la\n",
    "\n",
    "# Matricen har ikke fuld rank - se celle neden under (ogs√• hvis determinaten er nul! man kan jo ikke dividere med nul)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot take the inverse of `x`, what do we normaly need to check before we take the inverse? What `numpy.linalg` method can we use to help us check for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FILL IN HERE\n",
    "\n",
    "la.matrix_rank(matrix)\n",
    "\n",
    "# matricen har rank = 2, hvilket betyder at den ikke har fuld rank "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalar operations can be performed as usual with `*` and `/`, and behaves as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.  4.5]\n",
      " [0.5 1.5]]\n",
      "[[ 8 18]\n",
      " [ 2  6]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[4, 9], [1, 3]])\n",
    "print(a/2)\n",
    "print(a*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack vectors or matrices together\n",
    "If you have several 1-D vectors (has the shape (k,)), you can use `np.column_stack()` to get a matrix with the input vectors put together as column.\n",
    "\n",
    "If you have matrices (or arrays) that are multidimensional (have the shape (k, t)), you can use `np.hstack()` (means horizontal stack). This is very useful if you already have a matrix, and you want to add a vector.\n",
    "\n",
    "Try to make a matrix with two `row` vectors, this should give you a $9 \\times 2$ vector.\n",
    "\n",
    "Make a new vector, and add it to the `x` matrix. This should then be a $3 \\times 4$ matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 0],\n",
       "       [3, 4, 5, 0],\n",
       "       [6, 7, 8, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FILL IN HERE\n",
    "\n",
    "np.column_stack((row,row))\n",
    "\n",
    "new_vector = np.array([0,0,0])\n",
    "\n",
    "np.column_stack((x,new_vector))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other methods that you need to know.\n",
    "The numpy library is vast. Some other methods that are useful are `ones`, `diag`, `diagonal`, `eye`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Data generation\n",
    "### 1.1 \n",
    "Create a synthetic dataset with the following characteristics\n",
    "\n",
    "\\begin{align}\n",
    "    y_i &= \\beta_0 + x_{1i}\\beta_1 + x_{2i}\\beta_2 + \\varepsilon_i\n",
    "\\end{align}\n",
    "\n",
    "where $\\beta_0=1$, $\\beta_1 = -0.5$, $\\beta_2 = 2$, $x_{1i} \\sim \\mathcal{N}(0, 4)$, $x_{2i} \\sim \\mathcal{N}(5, 9)$, $\\varepsilon_i \\sim \\mathcal{N}(0, 1)$, and where $i = 0, ..., 99$. <br>\n",
    "The code may look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create a seed to always have identical draws.\n",
    "seed = 42\n",
    "# Instance a random number generator using this seed.\n",
    "rng = random.default_rng(seed=seed)\n",
    "n = 100\n",
    "betas = np.array([1, -0.5, 2]).reshape(-1, 1)\n",
    "\n",
    "# Make random draws from a normal distribution.\n",
    "def random_draws(n):\n",
    "    x0 = np.ones(n) # FILL IN HERE\n",
    "    x1 = rng.normal(0, 4, n) # np.array([rng.normal(0,4) for i in range(n)]) # FILL IN HERE\n",
    "    x2 = rng.normal(5, 9, n) # np.array([rng.normal(5,9) for i in range(n)])# FILL IN HERE\n",
    "    eps = rng.normal(0, 1, n).reshape(-1, 1) # np.array([rng.normal(0,1) for i in range(n)]) # FILL IN HERE\n",
    "    \n",
    "    # Stack the single columns into a matrix, return\n",
    "    # the matrix along with eps.\n",
    "    return np.column_stack((x0,x1,x2)), eps # FILL IN HERE, eps\n",
    "\n",
    "x, eps = random_draws(n)\n",
    "\n",
    "# Create y using the betas and X.\n",
    "y = x@betas + eps # FILL IN HERE\n",
    "print(y.shape) # does y have the dimensions you expect?\n",
    "\n",
    "# To get what I expected write:\n",
    "# y = x @ betas.flatten() + eps \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 \n",
    "Imagine that you had not generated the dataset yourself, but that you were given a similar data set that was already collected (generated) and ready to analyze. What would you observe and not observe in that data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - OLS\n",
    "### 2.1\n",
    "Make sure that you remember the mathematical equation for the OLS estimation, which we will later use to estimate the beta coefficients using date from the previous excercise. <br> \n",
    "**Write out the OLS estimator in matrix form:**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{\\boldsymbol{\\beta}} = \\text{Fill in here} $ \n",
    "\n",
    "$$\\boldsymbol{\\hat{\\beta}} = (\\mathbf{X}'\\mathbf{X})^{-1} \\mathbf{X'}\\mathbf{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint: Look it up on p.53 in Wooldridge*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "As you might remember, to perform inference on the OLS estimators, we need to calculate the standard errors for the previously estimates OLS coefficients. Again, make sure you remember its equation, *and write up the OLS standard errors in matrix form:*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{\\widehat{Var(\\boldsymbol{\\hat{\\beta}})}} = \\hat{\\sigma}^2 (\\mathbf{X'}\\mathbf{X)^{-1}}$, for $\\hat{\\sigma}^2 = \\frac{SSR}{N - K}$, <br>\n",
    "\n",
    "where $SSR = \\sum_{i=0}^{N - 1} {\\hat{u}}^2_i$, N is the number of observations, and K is the number of explanatory variables including the constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint: Look it up on p.55 in Wooldridge* <br>\n",
    "*Hint: Remember that the variance is a function of $\\hat{\\sigma}^2$, which is calculated using SSR*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3\n",
    "Estimate $\\boldsymbol{\\hat{\\beta}}$ from the synthetic data set. Furthermore, calculate standard errors and t-values (assuming that the assumptions of the classical linear regression model are satisfied). The code may look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_estimation(y, x):\n",
    "    # Make sure that y and x are 2-D.\n",
    "    y = y.reshape(-1, 1)\n",
    "    if len(x.shape)<2:\n",
    "        x = x.reshape(-1, 1)\n",
    "\n",
    "    # Estimate beta\n",
    "    b_hat =  la.inv((x.T@x))@(x.T@y) # Fill in here\n",
    "\n",
    "    # Calculate standard errors\n",
    "    residual = y - x@b_hat # Fill in here\n",
    "    sigma = residual.T@residual/(n - betas.size) # Fill in here\n",
    "    cov = sigma * la.inv(x.T@x) # Fill in here\n",
    "    se = np.sqrt(cov.diagonal()).reshape(-1, 1)  # The diagonal method returns 1d array. # Fill in here\n",
    "\n",
    "    # Calculate t-values\n",
    "    t_values = b_hat / se # Fill in here\n",
    "    return b_hat, se, t_values\n",
    "\n",
    "b_hat, se, t_values = ols_estimation(y, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python stores vectors as one-dimensional rather than two-dimensional objects. This can sometimes cause havoc when we want to compute matrix products. Compute the outer and inner products of the residuals from above using np.inner() and np.outer(). Compare these with your computed outer and inner products when using matrix multiplication @. When computing outer and inner products of a column vector, a, recall that a'a is the inner product and aa' is the outer product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(1, 1)\n",
      "(100, 100)\n",
      "103.88122746346109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[103.88122746]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = y - x@b_hat # FILL IN HERE\n",
    "print(res.shape)\n",
    "outer = np.outer(res,res) # FILL IN HERE\n",
    "inner = np.inner(res,res) # FILL IN HERE\n",
    "matmul_inner = res.T@res# FILL IN HERE\n",
    "matmul_outer = res@res.T# FILL IN HERE\n",
    "print(inner.shape)\n",
    "print(outer.shape)\n",
    "print(matmul_inner.shape)\n",
    "print(matmul_outer.shape)\n",
    "print(np.sum(np.diag(inner)))\n",
    "matmul_inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we flatten the residuals to be stored in Python's default mode (i.e. one-dimensional) what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "()\n",
      "(100, 100)\n",
      "()\n",
      "()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "103.8812274634611"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=res.flatten()\n",
    "print(res.shape)\n",
    "outer = np.outer(res,res) # FILL IN HERE (same as above)\n",
    "inner = np.inner(res,res) # FILL IN HERE (same as above)\n",
    "matmul_inner = res.T@res # FILL IN HERE (same as above)\n",
    "matmul_outer = res@res.T # FILL IN HERE (same as above)\n",
    "print(inner.shape)\n",
    "print(outer.shape)\n",
    "print(matmul_inner.shape)\n",
    "print(matmul_outer.shape)\n",
    "matmul_outer\n",
    "# key: np.inner and np.outer treat vectors as one dimensional i.e. (k,) whilst @ treats vectors as two dimensional matrices (k,1)\n",
    "# be careful to use the right operand when computing inner and outer products :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have written a code to print a table, using the `tabulate` package. You will need to add the row names for this code to work - each row contains a information about the different coefficients on the explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Estimates:\n",
      "\n",
      "        Œ≤      Œ≤ÃÇ      Se    t-value\n",
      "---  ----  ------  -----  ---------\n",
      "b_0   1.0   0.929  0.119        7.8\n",
      "b_1  -0.5  -0.503  0.034      -14.9\n",
      "b_2   2.0   2.002  0.012      168.9\n"
     ]
    }
   ],
   "source": [
    "def print_table(row_names, b, b_hat, se, t_values):\n",
    "    table = []\n",
    "\n",
    "    # Make a list, where each row contains the estimated and calculated values.\n",
    "    for index, name in enumerate(row_names):\n",
    "        table_row = [\n",
    "            name, b[index], b_hat[index], se[index], t_values[index]\n",
    "        ]\n",
    "        table.append(table_row)\n",
    "\n",
    "    # Print the list using the tabulate class.\n",
    "    headers = ['', '\\u03b2', '\\u03b2\\u0302 ', 'Se', 't-value']\n",
    "    print('OLS Estimates:\\n')\n",
    "    print(tabulate(table, headers, floatfmt=['', '.1f', '.3f', '.3f', '.1f']))\n",
    "\n",
    "row_names = ['b_0', 'b_1', 'b_2'] # Fill in here\n",
    "print_table(row_names, betas, b_hat, se, t_values) # Fill in here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can print a table which you can paste straight into latex using the following code. This uses panda data frames  which we'll cover next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      " & Œ≤ & Œ≤ÃÇ & se & t-values \\\\\n",
      "beta1 & [1.] & [0.9294] & [0.1192] & [7.797] \\\\\n",
      "beta2 & [-0.5] & [-0.5027] & [0.0336] & [-14.9481] \\\\\n",
      "beta3 & [2.] & [2.0016] & [0.0119] & [168.8937] \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dat = pd.DataFrame(zip(betas,b_hat.round(4),se.round(4),t_values.round(4)))\n",
    "dat.columns = ['\\u03b2','\\u03b2\\u0302','se','t-values']\n",
    "dat.index = ['beta1','beta2','beta3']\n",
    "print(dat.style.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - a simple Monte Carlo Experiment\n",
    "Carry out a Monte Carlo experiment with $S = 200$ replications and $N = 100$ observations to check if the OLS estimator provides an unbiased estimate of $\\boldsymbol{\\beta}$\n",
    "### 3.1\n",
    "Generate 200 data sets similar to what you did in exercise 1, and estimate $\\boldsymbol{\\beta}$ on each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint:* Start by making prefilling two arrays using `np.zeros`, one array to store the estimated beta coefficients, and one to store the estimated standard errors. What shape should these arrays have?\n",
    "\n",
    "Then make a loop where each loop makes a random draw, and then estimates on this random draw. And finally stores the estimated coefficients and standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variables and lists\n",
    "s = 200\n",
    "n = 100\n",
    "\n",
    "# Allocate memory for arrays to later fill\n",
    "b_coeffs = np.zeros((s, betas.size))\n",
    "b_ses = np.zeros((s, betas.size))\n",
    "\n",
    "for i in range(s):\n",
    "    # Generate data\n",
    "    x, eps = random_draws(n) # Fill in here\n",
    "    y = x@betas + eps # Fill in here\n",
    "\n",
    "    # Estimate coefficients and variance\n",
    "    b_hat, se, t_values = ols_estimation(y,x) # Fill in here\n",
    "\n",
    "    # Store estimates\n",
    "    b_coeffs[i, :] = b_hat.T # Fill in here\n",
    "    b_ses[i, :] = se.T # Fill in here\n",
    "\n",
    "# Make sure that there are no more zeros left in the arrays.\n",
    "assert np.all(b_coeffs) and np.all(b_ses), 'Not all coefficients or standard errors are non-zero.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2\n",
    "Do the following three calculations:\n",
    "- Calculate the means of the estimates (means across simulations)\n",
    "- Calculate the means of the standard errors (means across simulations)\n",
    "- Calculate the standard error of the MC estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_b_hat = np.mean(b_coeffs, axis=0) # Fill in here\n",
    "mean_b_se = np.mean(b_ses, axis=0) # Fill in here\n",
    "mean_mc_se = np.sqrt((np.sum(\n",
    "    (b_coeffs - np.mean(b_coeffs, axis=0))*(b_coeffs - np.mean(b_coeffs, axis=0)), axis=0)/(s - 1)\n",
    ")) # Fill in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5  2. ]]\n",
      "[ 1.00164271 -0.50142881  1.99866145]\n",
      "[0.11615686 0.02561331 0.01128654]\n",
      "[0.10904839 0.02626048 0.01174088]\n"
     ]
    }
   ],
   "source": [
    "print(betas.T)\n",
    "print(mean_b_hat)\n",
    "print(mean_b_se)\n",
    "print(mean_mc_se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3\n",
    "Draw a histogram for the 200 estimates of $\\beta_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fill in here\n",
    "\n",
    "# Use matplotlib to plot the histogram. If you use jupyter notebook, include \";\" to force\n",
    "# the notebook to not print the return value (the plt method also returns the two arrays it\n",
    "# use to plot the histogram, but we do not always want to see these).\n",
    "plt.hist(b_coeffs[:, 1], bins=20) ; "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
